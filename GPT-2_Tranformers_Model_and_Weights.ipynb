{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence 1: What is the full name of USA?\n",
      "\n",
      "What is your background?\n",
      "\n",
      "What is your job (doors, elevators, elevator)?\n",
      "[2061, 318, 262, 1336, 1438, 286, 4916, 30, 198, 198, 2061, 318, 534, 4469, 30, 198, 198, 2061, 318, 534, 1693, 357, 4598, 669, 11, 7662, 2024, 11, 20932, 19427]\n",
      "Generated Sequence 2: What is the full name of USA? USA = USA\n",
      "\n",
      "If we didn't already know our name, just what country was this name, or\n",
      "[2061, 318, 262, 1336, 1438, 286, 4916, 30, 4916, 796, 4916, 198, 198, 1532, 356, 1422, 470, 1541, 760, 674, 1438, 11, 655, 644, 1499, 373, 428, 1438, 11, 393]\n",
      "Generated Sequence 3: What is the full name of USA? USA is US/Toronto - (9) 887-2220, USA is Toronto - (9)\n",
      "[2061, 318, 262, 1336, 1438, 286, 4916, 30, 4916, 318, 1294, 14, 31359, 532, 357, 24, 8, 807, 5774, 12, 1828, 1238, 11, 4916, 318, 6586, 532, 357, 24, 8]\n",
      "Generated Sequence 4: What is the full name of USA?\n",
      "\n",
      "USA is the name given to all Canadian citizens living in Canada. It makes sense as the nation's\n",
      "[2061, 318, 262, 1336, 1438, 286, 4916, 30, 198, 198, 14053, 318, 262, 1438, 1813, 284, 477, 5398, 4290, 2877, 287, 3340, 13, 632, 1838, 2565, 355, 262, 3277, 338]\n",
      "Generated Sequence 5: What is the full name of USA?\n",
      "\n",
      "The U.S.S.R. is a legal collective name in Canada, New York City\n",
      "[2061, 318, 262, 1336, 1438, 286, 4916, 30, 198, 198, 464, 471, 13, 50, 13, 50, 13, 49, 13, 318, 257, 2742, 10098, 1438, 287, 3340, 11, 968, 1971, 2254]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.nn import functional as F\n",
    "\n",
    "max_length = 30 # maximal length of each return sqequence\n",
    "num_return_sequences = 5 # maximal number of return sequences\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "# gpt2, gpt2-medium, gpt2-large, and gpt2-xl\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "torch.manual_seed(43)\n",
    "torch.cuda.manual_seed(43)\n",
    "\n",
    "input_text = \"What is the full name of USA?\"\n",
    "tokens = tokenizer.encode(input_text, return_tensors='pt').to('cuda')\n",
    "# tokens = [15496, 11, 314, 1101, 257, 3303, 2746, 11]  # \"Hello, I'm a language model,\"\n",
    "# tokens = torch.tensor(tokens, dtype=torch.long)  # (8,)\n",
    "tokens = tokens.repeat(num_return_sequences, 1)  # Repeat tokens for the number of sequences\n",
    "x = tokens.to('cuda')\n",
    "\n",
    "# Generate! Right now x is (B, T) where B = 5, T = 8\n",
    "while x.size(1) < max_length:\n",
    "    with torch.no_grad():\n",
    "        logits = model(x).logits  # Forward the model to get the logits (B, T, vocab_size)\n",
    "        logits = logits[:, -1, :]  # Take the logits at the last position (B, vocab_size)\n",
    "        probs = F.softmax(logits, dim=-1)  # Get the probabilities\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)  # Top-k sampling of 50 (B, 50)\n",
    "        ix = torch.multinomial(topk_probs, 1)  # Select a token from the top-k probabilities (B, 1)\n",
    "        xcol = torch.gather(topk_indices, 1, ix)  # Gather the corresponding indices (B, 1)\n",
    "        x = torch.cat((x, xcol), dim=1)  # Append to the sequence\n",
    "\n",
    "# Print the generated text\n",
    "for i in range(num_return_sequences):\n",
    "    tokens = x[i, :max_length].tolist()\n",
    "    decoded = tokenizer.decode(tokens)\n",
    "    print(f\"Generated Sequence {i + 1}: {decoded}\")\n",
    "    print(f\"{tokens}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
